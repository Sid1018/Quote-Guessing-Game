{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "requests: This library is used to make HTTP requests to web pages. It's how we fetch the content of web pages.\n",
        "\n",
        "BeautifulSoup: This is a part of the bs4 library, which helps us parse HTML documents and extract data from them easily.\n",
        "\n",
        "writer: From the csv module, this would typically be used for writing data to CSV files. However, it's not used in the provided script.\n",
        "\n",
        "sleep: This function is used to pause the execution of the script for a given amount of time (in seconds). It's useful for not overloading the server with too many requests in a short period.\n",
        "\n",
        "choice: This function is used to randomly select an item from a list."
      ],
      "metadata": {
        "id": "hUV064XLQp7f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjT1waHmQC2p"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import writer\n",
        "from time import sleep\n",
        "from random import choice"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "all_quotes: This is an empty list that will store the quotes and their details (text, author, and a link to the author's bio) as dictionaries.\n",
        "\n",
        "base_url: This is the main part of the URL of the website we're scraping. It stays the same for every page.\n",
        "\n",
        "url: This part of the URL will change as we move from one page of quotes to another (e.g., /page/1, /page/2, etc.).\n"
      ],
      "metadata": {
        "id": "paQB1Vy6SK3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list to store scraped data\n",
        "all_quotes = []\n",
        "# this part of the url is constant\n",
        "base_url = \"http://quotes.toscrape.com/\"\n",
        "# this part of the url will keep changing\n",
        "url = \"/page/1\""
      ],
      "metadata": {
        "id": "avT622X2RpLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "while url:: This loop will continue as long as url is not None. It means we will keep scraping the website until there are no more pages to scrape.\n",
        "\n",
        "res = requests.get(f\"{base_url}{url}\"): This line combines the base URL with the current page URL to make a request to that specific page. res now contains the HTML content of that page.\n",
        "\n",
        "BeautifulSoup(res.text, \"html.parser\"): This line parses the HTML content using BeautifulSoup so that we can easily navigate and extract the necessary data.\n",
        "\n",
        "soup.find_all(class_=\"quote\"): This line finds all the HTML elements with the class quote. Each element corresponds to a quote block on the page.\n",
        "\n",
        "all_quotes.append({...}): This part extracts the text, author, and link to the author's bio from each quote and adds it as a dictionary to the all_quotes list.\n",
        "\n",
        "next_btn = soup.find(class_=\"next\"): This line looks for the \"Next\" button on the page, which allows us to go to the next page of quotes.\n",
        "\n",
        "url = next_btn.find(\"a\")[\"href\"] if next_btn\n",
        "\n",
        "else None: If the \"Next\" button is found, it extracts the href (URL) from it; otherwise, it sets url to None, ending the loop.\n",
        "\n",
        "sleep(2): This pauses the program for 2 seconds before making the next request. This helps to avoid overwhelming the server with too many requests."
      ],
      "metadata": {
        "id": "LjQy0xLlZ0vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while url:\n",
        "  res = requests.get(f\"{base_url}{url}\")\n",
        "  print(f\"Now Scraping{base_url}{url}\")\n",
        "  soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "  quotes = soup.find_all(class_=\"quote\")\n",
        "\n",
        "  for quote in quotes:\n",
        "    all_quotes.append({\n",
        "        \"text\": quote.find(class_=\"text\").get_text(),\n",
        "        \"author\": quote.find(class_=\"author\").get_text(),\n",
        "        \"bio-link\": quote.find(\"a\")[\"href\"]\n",
        "    })\n",
        "    next_btn = soup.find(class_=\"next\")\n",
        "    url = next_btn.find(\"a\")[\"href\"] if next_btn else None\n",
        "    sleep(2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeXD4pvwVjgZ",
        "outputId": "f2856e12-d99b-4e75-e19e-bdcbcf04d7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Scrapinghttp://quotes.toscrape.com//page/2/\n",
            "Now Scrapinghttp://quotes.toscrape.com//page/3/\n",
            "Now Scrapinghttp://quotes.toscrape.com//page/4/\n",
            "Now Scrapinghttp://quotes.toscrape.com//page/5/\n",
            "Now Scrapinghttp://quotes.toscrape.com//page/6/\n",
            "Now Scrapinghttp://quotes.toscrape.com//page/7/\n",
            "Now Scrapinghttp://quotes.toscrape.com//page/8/\n",
            "Now Scrapinghttp://quotes.toscrape.com//page/9/\n",
            "Now Scrapinghttp://quotes.toscrape.com//page/10/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "quote = choice(all_quotes): This line randomly selects one quote from the all_quotes list.\n",
        "remaining_guesses = 4: The user is given 4 attempts to guess the author.\n",
        "print(\"Here's a quote: \"): This prints a message to indicate that a quote will be shown.\n",
        "print(quote[\"text\"]): This displays the randomly selected quote's text."
      ],
      "metadata": {
        "id": "9rEvATCfaofe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quote = choice(all_quotes)\n",
        "remaining_guesses = 4\n",
        "print(\"Here's a quote:\")\n",
        "print(quote[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfy6ioC8aHl2",
        "outputId": "471fb184-3179-4f0d-f3f7-5b58bef73f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a quote:\n",
            "“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "guess = ''\n",
        "while guess.lower() != quote[\"author\"].lower() and remaining_guesses > 0:\n",
        "  guess = input(f\"Who said this quote? Guesses remaining: {remaining_guesses}\")\n",
        "  if guess.lower() == quote[\"author\"]:\n",
        "    print(\"Congratulations! you get it right\")\n",
        "    break\n",
        "    remaining_guesses -= 1\n",
        ""
      ],
      "metadata": {
        "id": "v0DrmFGygDkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When guesses are down to 3: It fetches the author's birth date and place from their bio link and gives that as a hint.\n",
        "\n",
        "When guesses are down to 2: It provides a hint with the first letter of the author's first name.\n",
        "\n",
        "When guesses are down to 1: It gives a hint with the first letter of the author's last name.\n"
      ],
      "metadata": {
        "id": "qUT5Uy_ijMTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\tif remaining_guesses == 3:\n",
        "\t\tres = requests.get(f\"{base_url}{quote['bio-link']}\")\n",
        "\t\tsoup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\t\tbirth_date = soup.find(class_=\"author-born-date\").get_text()\n",
        "\t\tbirth_place = soup.find(class_=\"author-born-location\").get_text()\n",
        "\t\tprint(f\"Here's a hint: The author was born on {birth_date} {birth_place}\")\n",
        "\n",
        "\telif remaining_guesses == 2:\n",
        "\t\tprint(f\"Here's a hint: The author's first name starts with: {quote['author'][0]}\")\n",
        "\n",
        "\telif remaining_guesses == 1:\n",
        "\t\tlast_initial = quote[\"author\"].split(\" \")[1][0]\n",
        "\t\tprint(f\"Here's a hint: The author's last name starts with: {last_initial}\")\n"
      ],
      "metadata": {
        "id": "wiBN-1HPjJeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "else:: If the user runs out of guesses, the game ends, and it reveals the correct answer."
      ],
      "metadata": {
        "id": "6XNHHGOTjYnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\telse:\n",
        "\t\tprint(f\"Sorry, you ran out of guesses. The answer was {quote['author']}\")\n"
      ],
      "metadata": {
        "id": "UWdTUG0HjVbS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}